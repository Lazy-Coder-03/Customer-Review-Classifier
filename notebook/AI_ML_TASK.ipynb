{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWOWmVweXIVB",
        "outputId": "150fe0b9-4e7b-4a1f-b99b-435a5d446e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Setting up Customer Query Classifier in Google Colab\n",
            "============================================================\n",
            "üì¶ Installing required packages...\n",
            "‚úÖ Installed torch>=2.0.0\n",
            "‚úÖ Installed transformers>=4.35.0\n",
            "‚úÖ Installed datasets>=2.12.0\n",
            "‚úÖ Installed scikit-learn>=1.3.0\n",
            "‚úÖ Installed pandas>=2.0.0\n",
            "‚úÖ Installed numpy>=1.24.0\n",
            "‚úÖ Installed matplotlib>=3.7.0\n",
            "‚úÖ Installed seaborn>=0.12.0\n",
            "‚úÖ Installed accelerate>=0.21.0\n",
            "‚úÖ Installed evaluate>=0.4.0\n",
            "‚úÖ Installed tqdm>=4.65.0\n",
            "‚úÖ Installed joblib>=1.3.0\n",
            "\n",
            "üîß Setup completed!\n",
            "You can now run the training script.\n",
            "\n",
            "‚úÖ All packages imported successfully!\n",
            "üî• PyTorch version: 2.8.0+cu126\n",
            "ü§ó Transformers version: 4.55.2\n",
            "üß† Scikit-learn version: 1.6.1\n",
            "üìä Pandas version: 2.2.2\n",
            "üöÄ GPU available: Tesla T4\n",
            "\n",
            "============================================================\n",
            "üéØ Ready to train the Customer Query Classifier!\n",
            "Run the training script to start fine-tuning the model.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "Created as part of Liberty Infospace hiring test ‚Äì not for production use without candidate's consent\n",
        "Author: Sayantan Ghosh\n",
        "GitHub: https://github.com/lazy-coder-03\n",
        "\"\"\"\n",
        "\n",
        "# Google Colab Setup Script\n",
        "print(\"üöÄ Setting up Customer Query Classifier in Google Colab\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Install required packages\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_package(package):\n",
        "    \"\"\"Install a package using pip\"\"\"\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n",
        "        print(f\"‚úÖ Installed {package}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to install {package}: {e}\")\n",
        "\n",
        "# Required packages\n",
        "packages = [\n",
        "    \"torch>=2.0.0\",\n",
        "    \"transformers>=4.35.0\",\n",
        "    \"datasets>=2.12.0\",\n",
        "    \"scikit-learn>=1.3.0\",\n",
        "    \"pandas>=2.0.0\",\n",
        "    \"numpy>=1.24.0\",\n",
        "    \"matplotlib>=3.7.0\",\n",
        "    \"seaborn>=0.12.0\",\n",
        "    \"accelerate>=0.21.0\",\n",
        "    \"evaluate>=0.4.0\",\n",
        "    \"tqdm>=4.65.0\",\n",
        "    \"joblib>=1.3.0\"\n",
        "]\n",
        "\n",
        "print(\"üì¶ Installing required packages...\")\n",
        "for package in packages:\n",
        "    install_package(package)\n",
        "\n",
        "print(\"\\nüîß Setup completed!\")\n",
        "print(\"You can now run the training script.\")\n",
        "\n",
        "# Import test\n",
        "try:\n",
        "    import torch\n",
        "    import transformers\n",
        "    import sklearn\n",
        "    import pandas as pd\n",
        "    print(f\"\\n‚úÖ All packages imported successfully!\")\n",
        "    print(f\"üî• PyTorch version: {torch.__version__}\")\n",
        "    print(f\"ü§ó Transformers version: {transformers.__version__}\")\n",
        "    print(f\"üß† Scikit-learn version: {sklearn.__version__}\")\n",
        "    print(f\"üìä Pandas version: {pd.__version__}\")\n",
        "\n",
        "    # Check if GPU is available\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"üöÄ GPU available: {torch.cuda.get_device_name(0)}\")\n",
        "    else:\n",
        "        print(\"üíª Running on CPU\")\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Import error: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üéØ Ready to train the Customer Query Classifier!\")\n",
        "print(\"Run the training script to start fine-tuning the model.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Created as part of Liberty Infospace hiring test ‚Äì not for production use without candidate's consent\n",
        "Author: Sayantan Ghosh\n",
        "GitHub: https://github.com/lazy-coder-03\n",
        "\"\"\"\n",
        "\n",
        "# Colab-optimized training script with preprocessing improvements\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import logging\n",
        "import warnings\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Check runtime environment\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"üöÄ Running in Google Colab\")\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"üíª Running locally\")\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# üîß Preprocessing function\n",
        "# -------------------------\n",
        "def clean_text(text):\n",
        "    \"\"\"Lowercase, remove punctuation, numbers & extra spaces.\"\"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \" url \", text)  # replace URLs\n",
        "    text = re.sub(r\"\\d+\", \" number \", text)          # replace numbers\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # remove punctuation\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()         # remove extra spaces\n",
        "    return text\n",
        "\n",
        "\n",
        "class ColabCustomerQueryClassifier:\n",
        "    \"\"\"Customer query classifier with preprocessing.\"\"\"\n",
        "\n",
        "    def __init__(self, model_name=\"distilbert-base-uncased\"):\n",
        "        self.model_name = model_name\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.labels = [\"Billing Issue\", \"Technical Problem\", \"Compliment\", \"Product Question\", \"Complaint\"]\n",
        "\n",
        "    def create_directories(self):\n",
        "        \"\"\"Ensure necessary directories exist.\"\"\"\n",
        "        directories = [\"data\", \"models\", \"output/logs\", \"output/metrics\", \"output/visualizations\"]\n",
        "        for directory in directories:\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "        print(\"üìÅ Created project directories\")\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \"\"\"Load and preprocess dataset.\"\"\"\n",
        "        df = pd.read_csv(\"data/train_data.csv\")\n",
        "        print(f\"üíæ Loaded {len(df)} training samples\")\n",
        "\n",
        "        # Apply cleaning to queries\n",
        "        df[\"query\"] = df[\"query\"].apply(clean_text)\n",
        "\n",
        "        # Encode labels\n",
        "        df[\"labels\"] = self.label_encoder.fit_transform(df[\"category\"])\n",
        "\n",
        "        # Stratified train-validation split\n",
        "        train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "            df[\"query\"].tolist(),\n",
        "            df[\"labels\"].tolist(),\n",
        "            test_size=0.2,\n",
        "            random_state=42,\n",
        "            stratify=df[\"labels\"]\n",
        "        )\n",
        "\n",
        "        print(f\"üìä Training samples: {len(train_texts)}, Validation samples: {len(val_texts)}\")\n",
        "        return train_texts, val_texts, train_labels, val_labels\n",
        "\n",
        "    def load_model_and_tokenizer(self):\n",
        "        \"\"\"Load pretrained model & tokenizer.\"\"\"\n",
        "        try:\n",
        "            print(f\"ü§ñ Loading {self.model_name}...\")\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                self.model_name, num_labels=len(self.labels)\n",
        "            )\n",
        "            print(\"‚úÖ Model and tokenizer loaded successfully\")\n",
        "\n",
        "            if self.tokenizer.pad_token is None:\n",
        "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error loading model: {e}\")\n",
        "            raise\n",
        "\n",
        "    def tokenize_data(self, texts, labels):\n",
        "        \"\"\"Convert text into tokenized Dataset.\"\"\"\n",
        "        print(\"üî§ Tokenizing data...\")\n",
        "        encodings = self.tokenizer(\n",
        "            texts,\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            max_length=128,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        dataset = Dataset.from_dict({\n",
        "            \"input_ids\": encodings[\"input_ids\"],\n",
        "            \"attention_mask\": encodings[\"attention_mask\"],\n",
        "            \"labels\": labels\n",
        "        })\n",
        "        return dataset\n",
        "\n",
        "    def compute_metrics(self, eval_pred):\n",
        "        \"\"\"Compute evaluation metrics during training.\"\"\"\n",
        "        predictions, labels = eval_pred\n",
        "        predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "        from sklearn.metrics import accuracy_score, f1_score\n",
        "        accuracy = accuracy_score(labels, predictions)\n",
        "        f1 = f1_score(labels, predictions, average=\"weighted\")\n",
        "\n",
        "        return {\"accuracy\": accuracy, \"f1\": f1}\n",
        "\n",
        "    def train_model(self, train_dataset, val_dataset):\n",
        "        \"\"\"Fine-tune the model with Colab-optimized hyperparameters.\"\"\"\n",
        "        print(\"üèãÔ∏è Starting model training...\")\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=\"./output/logs\",\n",
        "            num_train_epochs=10,\n",
        "            per_device_train_batch_size=16,\n",
        "            per_device_eval_batch_size=16,\n",
        "            warmup_steps=100,\n",
        "            weight_decay=0.05,\n",
        "            learning_rate=5e-5,\n",
        "            logging_dir=\"./output/logs\",\n",
        "            logging_steps=10,\n",
        "            eval_strategy=\"epoch\",\n",
        "            save_strategy=\"epoch\",\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model=\"f1\",\n",
        "            greater_is_better=True,\n",
        "            save_total_limit=2,\n",
        "            report_to=\"none\",\n",
        "            fp16=torch.cuda.is_available()\n",
        "        )\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "            tokenizer=self.tokenizer,\n",
        "            data_collator=DataCollatorWithPadding(tokenizer=self.tokenizer),\n",
        "            compute_metrics=self.compute_metrics,\n",
        "            callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        "        )\n",
        "\n",
        "        trainer.train()\n",
        "        print(\"‚úÖ Training completed!\")\n",
        "        return trainer\n",
        "\n",
        "    def save_model(self, trainer):\n",
        "        \"\"\"Save trained model, tokenizer, and label encoder.\"\"\"\n",
        "        output_path = \"models/fine_tuned_classifier\"\n",
        "        print(f\"üíæ Saving model to {output_path}...\")\n",
        "\n",
        "        trainer.save_model(output_path)\n",
        "        self.tokenizer.save_pretrained(output_path)\n",
        "\n",
        "        import joblib\n",
        "        joblib.dump(self.label_encoder, os.path.join(output_path, \"label_encoder.pkl\"))\n",
        "\n",
        "        print(\"‚úÖ Model saved successfully!\")\n",
        "\n",
        "    def run_training(self):\n",
        "        \"\"\"End-to-end pipeline.\"\"\"\n",
        "        try:\n",
        "            print(\"üöÄ Starting Customer Query Classifier Training Pipeline\")\n",
        "            print(\"=\" * 60)\n",
        "\n",
        "            self.create_directories()\n",
        "            self.load_model_and_tokenizer()\n",
        "            train_texts, val_texts, train_labels, val_labels = self.prepare_data()\n",
        "            train_dataset = self.tokenize_data(train_texts, train_labels)\n",
        "            val_dataset = self.tokenize_data(val_texts, val_labels)\n",
        "            trainer = self.train_model(train_dataset, val_dataset)\n",
        "            self.save_model(trainer)\n",
        "\n",
        "            print(\"=\" * 60)\n",
        "            print(\"üéâ Training pipeline completed successfully!\")\n",
        "            print(f\"üìÅ Model saved in: models/fine_tuned_classifier\")\n",
        "            return trainer\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Training failed: {e}\")\n",
        "            raise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCNdpn22ZYNT",
        "outputId": "4a40bb7f-49e1-4a36-db1c-7c2a2f51f5b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Running in Google Colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = ColabCustomerQueryClassifier()\n",
        "trainer = classifier.run_training()\n",
        "\n",
        "# Save after training\n",
        "trainer.save_model(\"models/fine_tuned_classifier\")\n",
        "classifier.tokenizer.save_pretrained(\"models/fine_tuned_classifier\")\n",
        "joblib.dump(classifier.label_encoder, \"models/fine_tuned_classifier/label_encoder.pkl\")\n",
        "\n",
        "print(\"‚úÖ Training done and model saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "g8mS52SOqMpd",
        "outputId": "7c66ffa8-7d2d-4b5f-8b64-f07e541d88e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting Customer Query Classifier Training Pipeline\n",
            "============================================================\n",
            "üìÅ Created project directories\n",
            "ü§ñ Loading distilbert-base-uncased...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model and tokenizer loaded successfully\n",
            "üíæ Loaded 990 training samples\n",
            "üìä Training samples: 792, Validation samples: 198\n",
            "üî§ Tokenizing data...\n",
            "üî§ Tokenizing data...\n",
            "üèãÔ∏è Starting model training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/500 01:09 < 01:10, 3.55 it/s, Epoch 5/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.356900</td>\n",
              "      <td>1.156790</td>\n",
              "      <td>0.752525</td>\n",
              "      <td>0.683755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.556600</td>\n",
              "      <td>0.368624</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.808965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.375900</td>\n",
              "      <td>0.329759</td>\n",
              "      <td>0.853535</td>\n",
              "      <td>0.848585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.218800</td>\n",
              "      <td>0.324302</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.845842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.280900</td>\n",
              "      <td>0.438027</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.829695</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Training completed!\n",
            "üíæ Saving model to models/fine_tuned_classifier...\n",
            "‚úÖ Model saved successfully!\n",
            "============================================================\n",
            "üéâ Training pipeline completed successfully!\n",
            "üìÅ Model saved in: models/fine_tuned_classifier\n",
            "‚úÖ Training done and model saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def quick_test(classifier, model, tokenizer, query):\n",
        "    \"\"\"Run a real-time prediction for a single query\"\"\"\n",
        "\n",
        "    try:\n",
        "        query = clean_text(query)\n",
        "        inputs = tokenizer(query, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "            predicted_class_id = predictions.argmax().item()\n",
        "            confidence = predictions.max().item()\n",
        "            predicted_label = classifier.label_encoder.inverse_transform([predicted_class_id])[0]\n",
        "        print(f\"  '{query}' ‚Üí {predicted_label} ({confidence:.2%})\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Prediction failed: {e}\")\n",
        "\n",
        "\n",
        "# Load back model + tokenizer + encoder\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"models/fine_tuned_classifier\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"models/fine_tuned_classifier\")\n",
        "classifier.label_encoder = joblib.load(\"models/fine_tuned_classifier/label_encoder.pkl\")\n",
        "\n",
        "print(\"üöÄ Real-time Customer Query Classifier\")\n",
        "print(\"Type 'exit' to quit.\\n\")\n",
        "\n",
        "while True:\n",
        "    review = input(\"Write a review to classify: \")\n",
        "    if review.lower().strip() == \"exit\":\n",
        "        print(\"üëã Exiting classifier. Goodbye!\")\n",
        "        break\n",
        "    quick_test(classifier, model, tokenizer, review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1M6y7oebLmy",
        "outputId": "b1a98eaf-69de-46db-fc2f-fc8933301824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Real-time Customer Query Classifier\n",
            "Type 'exit' to quit.\n",
            "\n",
            "Write a review to classify: what is payment method?\n",
            "  'what is payment method' ‚Üí Product Question (95.57%)\n",
            "Write a review to classify: awesome product\n",
            "  'awesome product' ‚Üí Compliment (49.19%)\n",
            "Write a review to classify: i cant login\n",
            "  'i cant login' ‚Üí Technical Problem (69.89%)\n",
            "Write a review to classify: exit\n",
            "üëã Exiting classifier. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZCiRwHLjlXAE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}